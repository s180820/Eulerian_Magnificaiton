{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import cv2 \n",
    "from main import *\n",
    "from itertools import cycle\n",
    "from plotly.validators.scatter.marker import SymbolValidator\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGauss(frame, levels):\n",
    "    pyramid = [frame]\n",
    "    for level in range(levels):\n",
    "        frame = cv2.pyrDown(frame)\n",
    "        pyramid.append(frame)\n",
    "    return pyramid\n",
    "\n",
    "def reconstructFrame(pyramid, index, levels, videoWidth=160, videoHeight=120):\n",
    "    filteredFrame = pyramid[index]\n",
    "    for level in range(levels):\n",
    "        filteredFrame = cv2.pyrUp(filteredFrame)\n",
    "    filteredFrame = filteredFrame[:videoHeight, :videoWidth]\n",
    "    return filteredFrame\n",
    "\n",
    "PROTOTXT_PATH = \"../../Models/Facial_recognition/deploy_prototxt.txt\"\n",
    "MODEL_PATH = \"../../Models/Facial_recognition/res10_300x300_ssd_iter_140000.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader from val_data folder\n",
    "video_list = []\n",
    "label_list = []\n",
    "\n",
    "for folder in os.listdir(\"val_data\"):\n",
    "    for file in os.listdir(\"val_data/\"+ folder):\n",
    "        if file.endswith(\".avi\"):\n",
    "            video_list.append(os.path.join(\"val_data/\"+folder, file))\n",
    "        elif file.endswith(\".rr\"):\n",
    "            label_list.append(os.path.join(\"val_data/\"+folder, file))\n",
    "\n",
    "#sort lists\n",
    "video_list.sort()\n",
    "label_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HR_CNN...\n",
      "extracting frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5562it [00:23, 237.23it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mae_hr_cnn_list = []\n",
    "mae_mtts_can_list = []\n",
    "mae_eulerian_list = []\n",
    "\n",
    "for i in range(len(video_list)):\n",
    "    rr = pd.read_csv(label_list[i], header=None)\n",
    "    #split data column into two columns\n",
    "    rr = rr[0].str.split(' ', expand=True)\n",
    "    rr = rr.rename(columns={0:'time', 1:'rr'})\n",
    "    hr = 60/rr['rr'].astype(float)\n",
    "    # repeat \"Ground Truth\" for 60 times\n",
    "    gt = np.repeat(\"Ground Truth\", 60)\n",
    "\n",
    "    # create dataframe for plot \n",
    "    data = np.array([range(1, 61), hr[:60].values, gt]).T\n",
    "    #plot_df = pd.DataFrame([*range(1, 61), hr[:60].values, gt], columns=[\"Time\", \"BPM\", \"type\"])\n",
    "    plot_df = pd.DataFrame(data = data, columns=[\"Time\", \"BPM\", \"type\"])\n",
    "\n",
    "    # add HR_CNN and MTTS_CAN data\n",
    "    test = Test_Methods(videoFileName = video_list[i])\n",
    "    hr_cnn = test.test_deep(method = \"HR_CNN\")\n",
    "    mtts_can = test.test_deep(method = \"MTTS_CAN\")\n",
    "    #make df for HR_CNN\n",
    "    hr_cnn_df = pd.DataFrame([range(7, 61), hr_cnn, np.repeat(\"HR_CNN\", 54)]).T\n",
    "    hr_cnn_df.columns = [\"Time\", \"BPM\", \"type\"]\n",
    "    #make df for MTTS_CAN\n",
    "    mtts_can_df = pd.DataFrame([range(7, 61), mtts_can, np.repeat(\"MTTS_CAN\", 54)]).T\n",
    "    mtts_can_df.columns = [\"Time\", \"BPM\", \"type\"]\n",
    "    #concatenate all dataframes\n",
    "    plot_df = pd.concat([plot_df, hr_cnn_df, mtts_can_df])\n",
    "    plot_df = plot_df.reset_index(drop=True)\n",
    "\n",
    "    cap2 = cv2.VideoCapture(video_list[i])\n",
    "    while cap2.isOpened():\n",
    "        ret, frame = cap2.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        #check if video has reached 60 seconds and break\n",
    "        if cap2.get(cv2.CAP_PROP_POS_MSEC) >= 60000:\n",
    "            break\n",
    "\n",
    "        webcam = cap2\n",
    "        realWidth = 500\n",
    "        realHeight = 500\n",
    "        videoWidth = 160\n",
    "        videoHeight = 120\n",
    "        videoChannels = 3\n",
    "        videoFrameRate = 15\n",
    "        webcam.set(3, realWidth)\n",
    "        webcam.set(4, realHeight)\n",
    "\n",
    "        # Color Magnification Parameters\n",
    "        levels = 3\n",
    "        alpha = 170\n",
    "        minFrequency = 1.0\n",
    "        maxFrequency = 2.0\n",
    "        bufferSize = 150\n",
    "        bufferIndex = 0\n",
    "\n",
    "        # Output Display Parameters\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        loadingTextLocation = (20, 30)\n",
    "        bpmTextLocation = (videoWidth // 2 + 5, 30)\n",
    "        fontScale = 1\n",
    "        fontColor = (255, 255, 255)\n",
    "        lineType = 2\n",
    "        boxColor = (0, 255, 0)\n",
    "        boxWeight = 3\n",
    "\n",
    "        # Initialize Gaussian Pyramid\n",
    "        firstFrame = np.zeros((300, 300, videoChannels))\n",
    "        firstGauss = buildGauss(firstFrame, levels + 1)[levels]\n",
    "        # firstGauss = buildLaplacian(firstFrame, levels+1)[levels]\n",
    "        videoGauss = np.zeros(\n",
    "            (bufferSize, firstGauss.shape[0], firstGauss.shape[1], videoChannels)\n",
    "        )\n",
    "        fourierTransformAvg = np.zeros((bufferSize))\n",
    "\n",
    "        # Bandpass Filter for Specified Frequencies\n",
    "        frequencies = (\n",
    "            (1.0 * videoFrameRate) * np.arange(bufferSize) / (1.0 * bufferSize)\n",
    "        )\n",
    "        mask = (frequencies >= minFrequency) & (frequencies <= maxFrequency)\n",
    "\n",
    "        # Heart Rate Calculation Variables\n",
    "        bpmCalculationFrequency = 15\n",
    "        bpmBufferIndex = 0\n",
    "        bpmBufferSize = 10\n",
    "        bpmBuffer = np.zeros((bpmBufferSize))\n",
    "\n",
    "        network = cv2.dnn.readNetFromCaffe(PROTOTXT_PATH, MODEL_PATH)\n",
    "        startY = 0\n",
    "        endY = 0\n",
    "        startX = 0\n",
    "        endX = 0\n",
    "\n",
    "        FIXED_BOX = False\n",
    "        fps = cap2.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        bpms=[]\n",
    "        bpms_hist = []\n",
    "        bpms_second = [0]\n",
    "        \n",
    "        time_idx = 1\n",
    "\n",
    "        i = 0\n",
    "        while True:\n",
    "            ret, frame = webcam.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            \n",
    "            (h, w) = frame.shape[:2]\n",
    "            if not FIXED_BOX:\n",
    "                blob = cv2.dnn.blobFromImage(\n",
    "                    cv2.resize(frame, (300, 300)),\n",
    "                    1.0,\n",
    "                    (300, 300),\n",
    "                    (104.0, 177.0, 123.0),\n",
    "                )\n",
    "                # Pass blot through network to perform facial detection\n",
    "                network.setInput(blob)\n",
    "                detections = network.forward()\n",
    "                count = 0\n",
    "\n",
    "                for i in range(0, detections.shape[2]):\n",
    "                    # Extract confidence assoficated with predictions.\n",
    "                    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                    # Filter based on confidence\n",
    "                    if confidence < 0.5:\n",
    "                        continue\n",
    "                    count += 1\n",
    "\n",
    "                    # compute BBOX\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                    # Draw box\n",
    "                    text = \"{:.2f}%\".format(confidence * 100) + \", Count: \" + str(count)\n",
    "                    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                    # cv2.rectangle(frame, (startX, startY),\n",
    "                    #               (endX, endY), (0, 255, 0), 2)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        text,\n",
    "                        (startX, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.45,\n",
    "                        (0, 255, 0),\n",
    "                        2,\n",
    "                    )\n",
    "            else:\n",
    "                startX = 720\n",
    "                startY = 150\n",
    "                endX = 1120\n",
    "                endY = 500\n",
    "            detectionFrame = frame[startY:endY, startX:endX, :]\n",
    "\n",
    "            # Construct Gaussian Pyramid\n",
    "            pyramid = buildGauss(detectionFrame, levels + 1)[levels]\n",
    "            # resize pyramid to fit videoGauss\n",
    "            pyramid = cv2.resize(\n",
    "                pyramid, (firstGauss.shape[0], firstGauss.shape[1])\n",
    "            )\n",
    "\n",
    "            videoGauss[bufferIndex] = pyramid\n",
    "            fourierTransform = np.fft.fft(videoGauss, axis=0)\n",
    "\n",
    "            # Bandpass Filter\n",
    "            fourierTransform[mask == False] = 0\n",
    "\n",
    "            # Grab a Pulse\n",
    "            if bufferIndex % bpmCalculationFrequency == 0:\n",
    "                i = i + 1\n",
    "                for buf in range(bufferSize):\n",
    "                    fourierTransformAvg[buf] = np.real(fourierTransform[buf]).mean()\n",
    "                hz = frequencies[np.argmax(fourierTransformAvg)]\n",
    "                bpm = 60.0 * hz\n",
    "                bpmBuffer[bpmBufferIndex] = bpm\n",
    "                bpmBufferIndex = (bpmBufferIndex + 1) % bpmBufferSize\n",
    "\n",
    "            # Amplify\n",
    "            filtered = np.real(np.fft.ifft(fourierTransform, axis=0))\n",
    "            filtered = filtered * alpha\n",
    "\n",
    "            # Reconstruct Resulting Frame\n",
    "            filteredFrame = reconstructFrame(\n",
    "                filtered,\n",
    "                bufferIndex,\n",
    "                levels,\n",
    "                videoHeight=endY - startY,\n",
    "                videoWidth=endX - startX,\n",
    "            )\n",
    "            filteredFrame = cv2.resize(\n",
    "                filteredFrame, (endX - startX, endY - startY)\n",
    "            )\n",
    "            outputFrame = detectionFrame + filteredFrame\n",
    "            outputFrame = cv2.convertScaleAbs(outputFrame)\n",
    "\n",
    "            bufferIndex = (bufferIndex + 1) % bufferSize\n",
    "\n",
    "            #if display_pyramid:\n",
    "            frame[startY:endY, startX:endX, :] = outputFrame\n",
    "            \n",
    "            cv2.rectangle(\n",
    "                frame, (startX, startY), (endX, endY), boxColor, boxWeight\n",
    "            )\n",
    "            if i > bpmBufferSize:\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    \"BPM: %d\" % bpmBuffer.mean(),\n",
    "                    bpmTextLocation,\n",
    "                    font,\n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    lineType,\n",
    "                )\n",
    "            else:\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    \"Calculating BPM...\",\n",
    "                    loadingTextLocation,\n",
    "                    font,\n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    lineType,\n",
    "                )\n",
    "\n",
    "            frame = cv2.cvtColor(\n",
    "                    frame, cv2.COLOR_BGR2RGB\n",
    "                )  # RGB Format to support streamlit\n",
    "            bpms.append(bpmBuffer.mean())\n",
    "            bpms_hist.append(bpmBuffer.mean())\n",
    "            #if len(bpms) > 200:\n",
    "                #   bpms = bpms[-200:]\n",
    "            # get hr for each second\n",
    "            if len(bpms) > 30:\n",
    "                bpm = np.mean(bpms[-30:])\n",
    "                bpms_second.append(bpm)\n",
    "                new_row = pd.DataFrame([[time_idx, bpm, \"Eulerian\"]], columns=[\"Time\", \"BPM\", \"type\"])\n",
    "                plot_df = pd.concat([plot_df, new_row])\n",
    "                time_idx += 1\n",
    "                bpms = []\n",
    "    plot_df.BPM = plot_df.BPM.astype(float)\n",
    "    fig = px.line(plot_df[plot_df[\"Time\"].astype(int) > 6], x=\"Time\", y=\"BPM\", \n",
    "                                    color=\"type\", labels={\"x\": \"Time\", \"y\": \"BPM\"},\n",
    "                                    title=\"Heart Rate Estimation on Bench Data\", width=1200, height=600)\n",
    "    raw_symbols = SymbolValidator().values\n",
    "    # Take only the string values which are in this order.\n",
    "    symbols_names = raw_symbols[::-2]\n",
    "    markers = cycle(symbols_names)\n",
    "\n",
    "    # set unique marker style for different countries\n",
    "    fig.update_traces(mode='lines+markers')\n",
    "    for d in fig.data:\n",
    "        d.marker.symbol = next(markers)\n",
    "        d.marker.size = 10\n",
    "    fig.show()\n",
    "\n",
    "    #calculate MAE between methods and ground truth\n",
    "    mae_hr_cnn = mean_absolute_error(plot_df[plot_df[\"type\"] == \"Ground Truth\"][\"BPM\"][:54].astype(float), \n",
    "                                 plot_df[plot_df[\"type\"] == \"HR_CNN\"][\"BPM\"].astype(float))\n",
    "    mae_mtts_can = mean_absolute_error(plot_df[plot_df[\"type\"] == \"Ground Truth\"][\"BPM\"][:54].astype(float),\n",
    "                                        plot_df[plot_df[\"type\"] == \"MTTS_CAN\"][\"BPM\"].astype(float))\n",
    "    mae_eulerian = mean_absolute_error(plot_df[plot_df[\"type\"] == \"Ground Truth\"][\"BPM\"][:51].astype(float),\n",
    "                                            plot_df[plot_df[\"type\"] == \"Eulerian\"][\"BPM\"][7:58].astype(float))\n",
    "    print(\"MAE HR_CNN: \", mae_hr_cnn)\n",
    "    print(\"MAE MTTS_CAN: \", mae_mtts_can)\n",
    "    print(\"MAE Eulerian: \", mae_eulerian)\n",
    "    mae_hr_cnn_list.append(mae_hr_cnn)\n",
    "    mae_mtts_can_list.append(mae_mtts_can)\n",
    "    mae_eulerian_list.append(mae_eulerian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
