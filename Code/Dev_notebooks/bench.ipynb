{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import bech_helper as helper\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_dir = \"././../../Data/Bench_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Custom dataset for the benchmark dataset\n",
    "    Args:\n",
    "        root_dir (string): Directory with all the videos.\n",
    "        createCSV (bool): If true, creates the csv files for the dataset and saves them in the same directory as the video.\n",
    "        createBBOX (bool): If true, creates the bounding boxes for the dataset and saves them in the same directory as the video.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, createCSV=False, createBBOX=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.video_files = []\n",
    "        self.csv_files = []\n",
    "        self.bbox_files = []\n",
    "        self.net = cv2.dnn.readNetFromCaffe(\n",
    "            prototxt=(\"../../Models/deploy.prototxt.txt\"),\n",
    "            caffeModel=(\n",
    "                \"../../Models/Facial_recognition/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if createCSV:\n",
    "            helper.converter_driver(self.root_dir)\n",
    "\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\"edited.avi\"):\n",
    "                    video_file = os.path.join(root, file)\n",
    "                    self.video_files.append(video_file)\n",
    "                if file.endswith(\"output.csv\"):\n",
    "                    csv_file = os.path.join(root, file)\n",
    "                    self.csv_files.append(csv_file)\n",
    "                if file.endswith(\"box.csv\"):\n",
    "                    bbox_file = os.path.join(root, file)\n",
    "                    self.bbox_files.append(bbox_file)\n",
    "        if createBBOX:\n",
    "            for i in range(len(self.video_files)):\n",
    "                video_file = self.video_files[i]\n",
    "                helper.start_video_feed(video_file, self.net)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_files[idx]\n",
    "        csv_path = self.csv_files[idx]\n",
    "        bbox_path = self.bbox_files[idx]\n",
    "\n",
    "        return (video_path, csv_path, bbox_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 5\n",
    "dataset = CustomDataset(root_dir=dataset_dir, createCSV=False, createBBOX=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('././../../Data/Bench_data/P2LC2/P2LC2_edited.avi',) ('././../../Data/Bench_data/P2LC2/P2LC2_Mobi_output.csv',) ('././../../Data/Bench_data/P2LC2/bbox.csv',)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    (video_path, csv_path, bbox_path) = batch\n",
    "print(video_path, csv_path, bbox_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra files that we need to use\n",
    "sys.path.append(\"../Skin_segmentation/\")\n",
    "sys.path.append(\"../../Models/\")\n",
    "\n",
    "# Import classes\n",
    "# import skin_detection_runefile as skin_driver\n",
    "from skin_video_driver import MultipleVideoDriver\n",
    "from rPPGNet import *\n",
    "from helper_functions import helper_functions\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Custom dataset for the benchmark dataset\n",
    "    Args:\n",
    "        root_dir (string): Directory with all the videos.\n",
    "        createCSV (bool): If true, creates the csv files for the dataset and saves them in the same directory as the video.\n",
    "        createBBOX (bool): If true, creates the bounding boxes for the dataset and saves them in the same directory as the video.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root_dir, createCSV=False, createBBOX=False, frames=64, verbosity=False\n",
    "    ):\n",
    "        self.root_dir = root_dir\n",
    "        self._class = \"[Custom dataset]\"\n",
    "        self.video_files = []\n",
    "        self.videoECG_counter = 0\n",
    "        self.csv_files = []\n",
    "        self.bbox_files = []\n",
    "        self.verbosity = verbosity\n",
    "        self.frames = frames\n",
    "        self.videoDriver = MultipleVideoDriver()\n",
    "        self.net = cv2.dnn.readNetFromCaffe(\n",
    "            prototxt=(\"../../Models/deploy.prototxt.txt\"),\n",
    "            caffeModel=(\n",
    "                \"../../Models/Facial_recognition/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "            ),\n",
    "        )\n",
    "        self.start_frame_idx = 1\n",
    "        self.current_frame_idx = self.start_frame_idx\n",
    "\n",
    "        if createCSV:\n",
    "            helper.converter_driver(self.root_dir)\n",
    "\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\"edited.avi\"):\n",
    "                    video_file = os.path.join(root, file)\n",
    "                    self.video_files.append(video_file)\n",
    "                if file.endswith(\"output.csv\"):\n",
    "                    csv_file = os.path.join(root, file)\n",
    "                    self.csv_files.append(csv_file)\n",
    "                if file.endswith(\"box.csv\"):\n",
    "                    bbox_file = os.path.join(root, file)\n",
    "                    self.bbox_files.append(bbox_file)\n",
    "        if createBBOX:\n",
    "            for i in range(len(self.video_files)):\n",
    "                video_file = self.video_files[i]\n",
    "                helper.start_video_feed(video_file, self.net)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_files)\n",
    "\n",
    "    def load_video_frames(self, video_path, bbdata, cur_frame_idx):\n",
    "        print(f\"{self._class} Converting\")\n",
    "        mask_array, frame_array = self.videoDriver.convert_video_with_progress(\n",
    "            video_file=video_path,\n",
    "            data=bbdata,\n",
    "            frames_to_process=self.frames + 1,\n",
    "            starting_frame=cur_frame_idx,\n",
    "            verbosity=False,\n",
    "        )\n",
    "        mask_array = helper_functions.binary_mask(mask_array)\n",
    "        return mask_array, frame_array\n",
    "\n",
    "    def load_ecg_data(self, ecg_path, start_frame, end_frame):\n",
    "        ecg = pd.read_csv(ecg_path)\n",
    "        ecg = ecg[\"ECG-A(mV)\"]\n",
    "        ecg = ecg[start_frame : end_frame + 1]\n",
    "        return ecg\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_files[idx]\n",
    "        ecg_path = self.csv_files[idx]\n",
    "        bbox_path = self.bbox_files[idx]\n",
    "\n",
    "        bb_data = pd.read_csv(bbox_path)\n",
    "        bb_data = bb_data[[\"X\", \"Y\", \"Width\", \"Height\"]]\n",
    "\n",
    "        column_mapping = {\n",
    "            \"X\": \"x\",\n",
    "            \"Y\": \"y\",\n",
    "            \"Width\": \"w\",\n",
    "            \"Height\": \"h\",\n",
    "        }\n",
    "        # Rename the columns using the dictionary\n",
    "        bb_data.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "        start_frame = self.current_frame_idx\n",
    "        video_frame_count = helper_functions.get_video_frame_count(video_path)\n",
    "        end_frame = start_frame + min(self.frames, video_frame_count - start_frame)\n",
    "\n",
    "        if self.verbosity:\n",
    "            print(\n",
    "                f\"{self._class} [INFO]: VideoFile: {video_path} | ECGFile: {ecg_path} |\"\n",
    "            )\n",
    "            print(\n",
    "                f\"{self._class} [INFO]: VideoCounter: {self.videoECG_counter} | FrameCounter: {start_frame} | TotalFrames: {video_frame_count}\"\n",
    "            )\n",
    "\n",
    "        mask_array, frame_array = self.load_video_frames(\n",
    "            video_path=video_path, bbdata=bb_data, cur_frame_idx=start_frame\n",
    "        )\n",
    "        ecg = self.load_ecg_data(\n",
    "            ecg_path=ecg_path, start_frame=start_frame, end_frame=end_frame\n",
    "        )\n",
    "\n",
    "        skin_seg_label, frame_tensor, ecg_tensor = helper_functions.tensor_transform(\n",
    "            mask_array, frame_array, ecg, self.frames\n",
    "        )\n",
    "        self.current_frame_idx = end_frame\n",
    "\n",
    "        if (not frame_tensor.shape[1] == self.frames) or (\n",
    "            not ecg_tensor.shape[0] == self.frames\n",
    "        ):\n",
    "            # print(\"Length of ecg GT\", ecg_tensor.shape[0])\n",
    "            # print(\"Number of frames:\", frame_tensor.shape[1])\n",
    "            if self.verbosity:\n",
    "                print(f\"{self._class} [DEBUGGING]\", start_frame)\n",
    "                print(\n",
    "                    f\"{self._class} [DEBUGGING] Video frames available\",\n",
    "                    video_frame_count,\n",
    "                )\n",
    "                # for i in range(5000):\n",
    "                print(f\"{self._class} [INFO] GETTING NEW VIDEO!\")\n",
    "            self.videoECG_counter += 1\n",
    "            self.current_frame_idx = self.start_frame_idx\n",
    "        if end_frame + self.frames >= video_frame_count:\n",
    "            # Move to the next video\n",
    "            self.videoECG_counter += 1\n",
    "            self.current_frame_idx = self.start_frame_idx\n",
    "\n",
    "        return skin_seg_label, frame_tensor, ecg_tensor\n",
    "\n",
    "    def get_dataloader(self, batch_size=1, *args, **kwargs):\n",
    "        if self.purpose == \"train\":\n",
    "            return DataLoader(\n",
    "                dataset=self.train_subset,\n",
    "                shuffle=True,\n",
    "                batch_size=batch_size,\n",
    "                *args,\n",
    "                **kwargs,\n",
    "            )\n",
    "        if self.purpose == \"test\":\n",
    "            return DataLoader(\n",
    "                dataset=self.test_subset,\n",
    "                shuffle=False,\n",
    "                batch_size=batch_size,\n",
    "                *args,\n",
    "                **kwargs,\n",
    "            )\n",
    "        if self.purpose == \"val\":\n",
    "            return DataLoader(\n",
    "                dataset=self.val_subset,\n",
    "                shuffle=False,\n",
    "                batch_size=batch_size,\n",
    "                *args,\n",
    "                **kwargs,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "dataset = CustomDataset(\n",
    "    root_dir=dataset_dir, createCSV=False, createBBOX=False, verbosity=True\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1LC1/P1LC1-edited.avi | ECGFile: ././../../Data/Bench_data/P1LC1/P1LC1_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 1 | TotalFrames: 5567\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1LC2/P1LC2_edited.avi | ECGFile: ././../../Data/Bench_data/P1LC2/P1LC2_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 65 | TotalFrames: 5562\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1H1/P1H1_edited.avi | ECGFile: ././../../Data/Bench_data/P1H1/P1H1_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 129 | TotalFrames: 9019\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1M1/P1M1_edited.avi | ECGFile: ././../../Data/Bench_data/P1M1/P1M1_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 193 | TotalFrames: 5860\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P2LC3/P2LC3_edited.avi | ECGFile: ././../../Data/Bench_data/P2LC3/P2LC3_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 257 | TotalFrames: 5415\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1M3/P1M3_edited.avi | ECGFile: ././../../Data/Bench_data/P1M3/P1M3_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 321 | TotalFrames: 5701\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P3LC5/P3LC5_edited.avi | ECGFile: ././../../Data/Bench_data/P3LC5/P3LC5_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 385 | TotalFrames: 5431\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P2LC4/P2LC4_edited.avi | ECGFile: ././../../Data/Bench_data/P2LC4/P2LC4_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 449 | TotalFrames: 5454\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P3LC2/P3LC2_edited.avi | ECGFile: ././../../Data/Bench_data/P3LC2/P3LC2_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 513 | TotalFrames: 5583\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P3LC3/P3LC3_edited.avi | ECGFile: ././../../Data/Bench_data/P3LC3/P3LC3_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 577 | TotalFrames: 5426\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P2LC5/P2LC5_edited.avi | ECGFile: ././../../Data/Bench_data/P2LC5/P2LC5_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 641 | TotalFrames: 5450\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1LC5/P1LC5_edited.avi | ECGFile: ././../../Data/Bench_data/P1LC5/P1LC5_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 705 | TotalFrames: 5558\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1M2/P1M2_edited.avi | ECGFile: ././../../Data/Bench_data/P1M2/P1M2_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 769 | TotalFrames: 5855\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1LC4/P1LC4_edited.avi | ECGFile: ././../../Data/Bench_data/P1LC4/P1LC4_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 833 | TotalFrames: 5543\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1LC7/P1LC7_edited.avi | ECGFile: ././../../Data/Bench_data/P1LC7/P1LC7_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 897 | TotalFrames: 5555\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1LC3/P1LC3_edited.avi | ECGFile: ././../../Data/Bench_data/P1LC3/P1LC3_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 961 | TotalFrames: 5681\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P2LC1/P2LC1_edited.avi | ECGFile: ././../../Data/Bench_data/P2LC1/P2LC1_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 1025 | TotalFrames: 5466\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P1LC6/P1LC6_edited.avi | ECGFile: ././../../Data/Bench_data/P1LC6/P1LC6_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 1089 | TotalFrames: 5554\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P3LC1/P3LC1_edited.avi | ECGFile: ././../../Data/Bench_data/P3LC1/P3LC1_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 1153 | TotalFrames: 5437\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P3LC4/P3LC4_edited.avi | ECGFile: ././../../Data/Bench_data/P3LC4/P3LC4_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 1217 | TotalFrames: 5432\n",
      "[Custom dataset] Converting\n",
      "[Custom dataset] [INFO]: VideoFile: ././../../Data/Bench_data/P2LC2/P2LC2_edited.avi | ECGFile: ././../../Data/Bench_data/P2LC2/P2LC2_Mobi_output.csv |\n",
      "[Custom dataset] [INFO]: VideoCounter: 0 | FrameCounter: 1281 | TotalFrames: 5429\n",
      "[Custom dataset] Converting\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    skin_seg_label, frame_tensor, ecg_tensor = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
